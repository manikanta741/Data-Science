{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNnVHkRxinnjyZFKQfuxv/q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manikanta741/Data-Science/blob/main/normalisation%20and%20standardisation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01wLPIGcdZu9",
        "outputId": "c8e1423e-9923-44cd-9ba5-715145410a27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Name   Age   Salary\n",
            "0    Alice  25.0  50000.0\n",
            "1      Bob   NaN  60000.0\n",
            "2  Charlie  30.0      NaN\n",
            "3     None  22.0  45000.0\n"
          ]
        }
      ],
      "source": [
        "#Normalization & Standardization\n",
        "\"\"\"Normalization (Min-Max Scaling)\n",
        "Scales data to a fixed range (0 to 1).\n",
        "Best for bounded datasets (e.g., prices, percentages).\"\"\"\n",
        "import pandas as pd\n",
        "data = {'Name': ['Alice', 'Bob', 'Charlie', None],\n",
        "        'Age': [25, None, 30, 22],\n",
        "        'Salary': [50000, 60000, None, 45000]}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#min max scaling\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "df[['Salary', 'Age']] = scaler.fit_transform(df[['Salary', 'Age']])\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Sd6ddRPeLi-",
        "outputId": "8162dd09-33a7-4b65-d00e-b3f4f095890f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Name    Age    Salary\n",
            "0    Alice  0.375  0.333333\n",
            "1      Bob    NaN  1.000000\n",
            "2  Charlie  1.000       NaN\n",
            "3     None  0.000  0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardization z-score scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df[['Salary', 'Age']] = scaler.fit_transform(df[['Salary', 'Age']])\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSA9rCbreadh",
        "outputId": "2835834f-8aec-4980-c376-22436da2af78"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Name       Age    Salary\n",
            "0    Alice -0.202031 -0.267261\n",
            "1      Bob       NaN  1.336306\n",
            "2  Charlie  1.313198       NaN\n",
            "3     None -1.111168 -1.069045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pqwJ7aAxey4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#encoding Categorical Variables\n",
        "#Machine learning models only work with numerical data, so categorical features must be converted.\n",
        "\"\"\"One-Hot Encoding (For Nominal Data)\n",
        "Creates binary (0/1) columns for each category.\n",
        "Useful when categories donâ€™t have order (e.g., \"City\", \"Color\").\"\"\"\n",
        "#df = pd.get_dummies(df, columns=['Category'], drop_first=True)\n",
        "\n",
        "\n",
        "\"\"\"ðŸ‘‰ Example:\n",
        "Before:\n",
        "\n",
        "Color:\n",
        "Red\n",
        "Blue\n",
        "Green\n",
        "After One-Hot Encoding:\n",
        "\n",
        "Color_Blue\tColor_Green\tColor_Red\n",
        "0\t0\t1\n",
        "1\t0\t0\n",
        "0\t1\t0\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5AtDnGabezjP",
        "outputId": "338ae7cb-e9a6-4909-885e-be25f7b75032"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ðŸ‘‰ Example:\\nBefore:\\n\\nColor:\\nRed\\nBlue\\nGreen\\nAfter One-Hot Encoding:\\n\\nColor_Blue\\tColor_Green\\tColor_Red\\n0\\t0\\t1\\n1\\t0\\t0\\n0\\t1\\t0\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Label Encoding (For Ordinal Data)\n",
        "Assigns numbers to categories based on their order.\n",
        "Use when categories have a ranking (e.g., \"Low\", \"Medium\", \"High\").\"\"\"\n",
        "\n",
        "\"\"\"Label Encoding (For Ordinal Data)\n",
        "Assigns numbers to categories based on their order.\n",
        "Use when categories have a ranking (e.g., \"Low\", \"Medium\", \"High\").\"\"\"\n",
        "\n",
        "\n",
        "#code\n",
        "#from sklearn.preprocessing import LabelEncoder\n",
        "#le = LabelEncoder()\n",
        "#df['Size'] = le.fit_transform(df['Size'])\n",
        "#\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ITbk8CNjffvo",
        "outputId": "e99c4314-1093-4893-c32e-a479526247f3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"code\\n\\n\\nfrom sklearn.preprocessing import LabelEncoder\\n\\nle = LabelEncoder()\\ndf['Size'] = le.fit_transform(df['Size'])\\n\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Dimensionality Reduction (PCA)\n",
        "\"\"\"High-dimensional data can lead to overfitting and slow training. PCA helps reduce dimensions while keeping most information.\n",
        "\n",
        "âœ… Principal Component Analysis (PCA)\n",
        "Reduces correlated features into uncorrelated principal components.\n",
        "Keeps only the most important information.\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "#from sklearn.decomposition import PCA\n",
        "#pca = PCA(n_components=2)  # Reduce to 2 dimensions\n",
        "#df_pca = pca.fit_transform(df[['Salary', 'Age', 'Experience']])\n"
      ],
      "metadata": {
        "id": "wtaJXk0QgSAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Technique\t    Purpose\n",
        "Normalization\t    Scale data to range (0-1)\n",
        "Standardization\t  Make mean = 0, std = 1\n",
        "One-Hot Encoding\tConvert categorical to multiple columns\n",
        "Label Encoding\t  Convert ordinal categories to numbers\n",
        "Feature Interacti\tCreate new insights from existing features\n",
        "Binning\tConvert   continuous variables to categories\n",
        "PCA\t              Reduce dimensionality\"\"\""
      ],
      "metadata": {
        "id": "r6SWVkYqg4kx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}