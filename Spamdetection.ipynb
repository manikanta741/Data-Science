{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPEt3hHO9MmAoXyNGhvXP73",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manikanta741/Data-Science/blob/main/Spamdetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keZl3nb7slrK",
        "outputId": "0912a64b-4520-489b-a5fb-8ff35abcc798"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     v1                                                 v2 Unnamed: 2  \\\n",
            "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
            "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
            "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
            "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
            "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
            "\n",
            "  Unnamed: 3 Unnamed: 4  \n",
            "0        NaN        NaN  \n",
            "1        NaN        NaN  \n",
            "2        NaN        NaN  \n",
            "3        NaN        NaN  \n",
            "4        NaN        NaN  \n",
            "v1               0\n",
            "v2               0\n",
            "Unnamed: 2    5522\n",
            "Unnamed: 3    5560\n",
            "Unnamed: 4    5566\n",
            "dtype: int64\n",
            "Index(['v1', 'v2', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], dtype='object')\n",
            "  label                                            message\n",
            "0   ham  Go until jurong point, crazy.. Available only ...\n",
            "1   ham                      Ok lar... Joking wif u oni...\n",
            "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3   ham  U dun say so early hor... U c already then say...\n",
            "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
            "label      0\n",
            "message    0\n",
            "dtype: int64\n",
            "   label                                            message\n",
            "0      0  Go until jurong point, crazy.. Available only ...\n",
            "1      0                      Ok lar... Joking wif u oni...\n",
            "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3      0  U dun say so early hor... U c already then say...\n",
            "4      0  Nah I don't think he goes to usf, he lives aro...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-114-14e5705cf2a8>:31: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data.rename(columns={'v1': 'label', 'v2': 'message'}, inplace=True)\n",
            "<ipython-input-114-14e5705cf2a8>:33: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['label'] = data['label'].map({'ham': 0, 'spam': 1})\n",
            "<ipython-input-114-14e5705cf2a8>:43: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data.dropna(inplace=True)\n",
            "<ipython-input-114-14e5705cf2a8>:46: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['label'] = data['label'].astype(int)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Punkt Tokenizer Found at: /root/nltk_data/tokenizers/punkt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             message  \\\n",
            "0  Go until jurong point, crazy.. Available only ...   \n",
            "1                      Ok lar... Joking wif u oni...   \n",
            "2  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
            "3  U dun say so early hor... U c already then say...   \n",
            "4  Nah I don't think he goes to usf, he lives aro...   \n",
            "\n",
            "                                     cleaned_message  \n",
            "0  go jurong point crazy available bugis n great ...  \n",
            "1                            ok lar joking wif u oni  \n",
            "2  free entry 2 wkly comp win fa cup final tkts 2...  \n",
            "3                u dun say early hor u c already say  \n",
            "4             nah think goes usf lives around though  \n",
            "(4457,)\n",
            "(1115,)\n",
            "(4457,)\n",
            "(1115,)\n",
            "label\n",
            "0    3859\n",
            "1     598\n",
            "Name: count, dtype: int64\n",
            "Model Accuracy: 96.95%\n",
            "Spam\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score,accuracy_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset with proper encoding\n",
        "data = pd.read_csv(\"/content/spam.csv\", encoding='latin-1')\n",
        "\n",
        "# Check the first few rows\n",
        "print(data.head())\n",
        "print(data.isnull().sum())\n",
        "\n",
        "print(data.columns)\n",
        "\n",
        "\n",
        "# Rename columns to meaningful names\n",
        "data = data[['v1', 'v2']]  # Keep only useful columns\n",
        "data.columns = ['label', 'message']  # Rename columns\n",
        "\n",
        "# Display first few rows after renaming\n",
        "print(data.head())\n",
        "\n",
        "\n",
        "data.rename(columns={'v1': 'label', 'v2': 'message'}, inplace=True)\n",
        "# Convert labels to binary\n",
        "data['label'] = data['label'].map({'ham': 0, 'spam': 1})\n",
        "\n",
        "# Check for missing values\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# Display first few rows\n",
        "print(data.head())\n",
        "\n",
        "\n",
        "# Drop any NaN rows (if found)\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# Ensure label column is of integer type\n",
        "data['label'] = data['label'].astype(int)\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt', force=True)\n",
        "\n",
        "\n",
        "import nltk.data\n",
        "tokenizer_path = nltk.data.find('tokenizers/punkt')\n",
        "print(\"Punkt Tokenizer Found at:\", tokenizer_path)\n",
        "nltk.download('punkt')\n",
        "\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download necessary data\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt',force=True)\n",
        "\n",
        "# Define text preprocessing function\n",
        "def clean_text(text):\n",
        "    if isinstance(text, float):  # Check if text is NaN\n",
        "        return \"\"\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = re.sub(r'\\W', ' ', text)  # Remove special characters\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
        "    words = text.split()\n",
        "\n",
        "    words = [word for word in words if word not in stopwords.words('english')]  # Remove stopwords\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Apply cleaning function to messages\n",
        "data['cleaned_message'] = data['message'].apply(clean_text)\n",
        "\n",
        "# Display sample cleaned messages\n",
        "print(data[['message', 'cleaned_message']].head())\n",
        "\n",
        "# üöÄ 9Ô∏è‚É£ Define features (X) and target (y)\n",
        "x= data['cleaned_message']  # Features (cleaned text)\n",
        "y = data['label']  # Labels (0 for ham, 1 for spam)\n",
        "\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42,stratify=y)\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "print(y_train.value_counts())  # Now should have both 0 and 1\n",
        "\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "x_train_tfidf = vectorizer.fit_transform(x_train)  # Fit & transform training data\n",
        "x_test_tfidf = vectorizer.transform(x_test)  # Transform test data\n",
        "\n",
        "\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(x_train_tfidf, y_train)\n",
        "\n",
        "\n",
        "y_pred = model.predict(x_test_tfidf)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "\n",
        "# New message for prediction\n",
        "new_message = [\"You have won a lottery! Claim now.\"]\n",
        "\n",
        "# Convert to TF-IDF format\n",
        "new_message_tfidf = vectorizer.transform(new_message)\n",
        "\n",
        "# Predict using the trained model\n",
        "prediction = model.predict(new_message_tfidf)\n",
        "\n",
        "# Display result\n",
        "print(\"Spam\" if prediction[0] == 1 else \"Ham\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# New message for prediction\n",
        "new_message = [\"Hey, are you coming to the party tonight?\"]\n",
        "\n",
        "# Convert to TF-IDF format\n",
        "new_message_tfidf = vectorizer.transform(new_message)\n",
        "\n",
        "# Predict using the trained model\n",
        "prediction = model.predict(new_message_tfidf)\n",
        "\n",
        "# Display result\n",
        "print(\"Spam\" if prediction[0] == 1 else \"Ham\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cW0-pC4b8J2W",
        "outputId": "309efad8-0ea1-4762-bff6-911a6ee65e27"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ham\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3BzS_8Ba0Iwm"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CRkYdefC0h1R"
      },
      "execution_count": 91,
      "outputs": []
    }
  ]
}